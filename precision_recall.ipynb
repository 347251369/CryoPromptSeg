{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "def coordinates_to_dmatrix(a_coords, b_coords):\n",
    "    a, b = torch.from_numpy(a_coords), torch.from_numpy(b_coords)\n",
    "    return np.array(torch.cdist(a,b))\n",
    "\n",
    "def object_detection_intersection_over_union(gt, pred, hsl=None, box_format=\"midpoint\"):\n",
    "    \"\"\"\n",
    "    Calculates the Intersection over Union (IoU) for object detection.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gt : numpy.ndarray\n",
    "        Ground truth bounding boxes with shape (N, 2) if `box_format` is \"midpoint\" or (N, 4) if `box_format` is \"corners\".\n",
    "\n",
    "    pred : numpy.ndarray\n",
    "        Predicted bounding boxes with shape (N, 2) if `box_format` is \"midpoint\" or (N, 4) if `box_format` is \"corners\".\n",
    "\n",
    "    hsl : float or numpy.ndarray, optional\n",
    "        Half side length of the bounding boxes when `box_format` is \"midpoint\". Ignored if `box_format` is \"corners\".\n",
    "\n",
    "    box_format : str, optional\n",
    "        Format of the bounding boxes. Either \"midpoint\" (default) or \"corners\".\n",
    "        - \"midpoint\": Bounding boxes are defined by their center coordinates and half side length (hsl).\n",
    "        - \"corners\": Bounding boxes are defined by their corner coordinates [xmin, ymin, xmax, ymax].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        IoU values for each pair of ground truth and predicted bounding boxes.\n",
    "    \"\"\"\n",
    "    if box_format == \"midpoint\":\n",
    "        # Calculate the corners of the bounding boxes\n",
    "        xmin1, xmax1, ymin1, ymax1 = gt[:, 0] - hsl, gt[:, 0] + hsl, gt[:, 1] - hsl, gt[:, 1] + hsl\n",
    "        xmin2, xmax2, ymin2, ymax2 = pred[:, 0] - hsl, pred[:, 0] + hsl, pred[:, 1] - hsl, pred[:, 1] + hsl\n",
    "    elif box_format == \"corners\":\n",
    "        xmin1, xmax1, ymin1, ymax1 = gt[:, 0], gt[:, 2], gt[:, 1], gt[:, 3]\n",
    "        xmin2, xmax2, ymin2, ymax2 = pred[:, 0], pred[:, 2], pred[:, 1], pred[:, 3]\n",
    "\n",
    "    # Calculate intersection area\n",
    "    xmin = np.max(np.concatenate((xmin1[:, None], xmin2[:, None]), axis=1), axis=1)\n",
    "    ymin = np.max(np.concatenate((ymin1[:, None], ymin2[:, None]), axis=1), axis=1)\n",
    "    xmax = np.min(np.concatenate((xmax1[:, None], xmax2[:, None]), axis=1), axis=1)\n",
    "    ymax = np.min(np.concatenate((ymax1[:, None], ymax2[:, None]), axis=1), axis=1)\n",
    "\n",
    "    # Calculate intersection area\n",
    "    intersection = np.clip(xmax - xmin, 0, None) * np.clip(ymax - ymin, 0, None)\n",
    "\n",
    "    # Calculate area of the bounding boxes\n",
    "    box1_area = abs((xmax1 - xmin1) * (ymax1 - ymin1))\n",
    "    box2_area = abs((xmax2 - xmin2) * (ymax2 - ymin2))\n",
    "\n",
    "    # Calculate union area\n",
    "    union = np.clip(box1_area + box2_area - intersection, 1e-6, None)\n",
    "\n",
    "    # Calculate and return IoU\n",
    "    return intersection / union\n",
    "  \n",
    "# def object_detection_intersection_over_union(gt, pred, r):\n",
    "#     \"\"\"\n",
    "#     计算两个圆（由中心点和半径定义）之间的 IoU。\n",
    "#     - gt: [N, 2]，真实圆的质心坐标\n",
    "#     - pred: [N, 2]，预测圆的质心坐标（必须与 gt 一一对应）\n",
    "#     - r: float 或 [N] 数组，圆的半径，gt 和 pred 半径一致\n",
    "\n",
    "#     返回：\n",
    "#     - ious: [N] 数组，每对圆之间的 IoU\n",
    "#     \"\"\"\n",
    "#     # 将输入统一为 numpy 数组\n",
    "#     gt = np.asarray(gt)\n",
    "#     pred = np.asarray(pred)\n",
    "#     r = np.asarray(r)\n",
    "\n",
    "#     # 检查变量 r 的维度是否为 0，即 r 是否是一个标量（单个数值）\n",
    "#     if r.ndim == 0:\n",
    "#         r = np.full(len(gt), r)\n",
    "\n",
    "#     # 计算欧氏距离\n",
    "#     d = np.linalg.norm(gt - pred, axis=1)   # 每对中心点之间的欧氏距离\n",
    "#     r1 = r2 = r  # 假设真实和预测圆的半径相同\n",
    "#     ious = np.zeros_like(d)  # 初始化结果\n",
    "\n",
    "#     area1 = np.pi * r1**2  #两个圆的面积。\n",
    "#     area2 = np.pi * r2**2\n",
    "\n",
    "#     # 对每对圆进行 IoU 计算\n",
    "#     for i in range(len(d)):\n",
    "#         if d[i] >= r1[i] + r2[i]:\n",
    "#             intersection = 0.0  # 不相交\n",
    "#         elif d[i] <= abs(r1[i] - r2[i]):\n",
    "#             intersection = np.pi * min(r1[i], r2[i])**2  # 完全包含\n",
    "#         else:\n",
    "#             # 部分相交，几何公式\n",
    "#             # part1, part2: 两个圆相交扇形的面积；\n",
    "#             part1 = r1[i]**2 * np.arccos((d[i]**2 + r1[i]**2 - r2[i]**2) / (2 * d[i] * r1[i]))\n",
    "#             # part3: 两个圆相交区域中三角形的面积；\n",
    "#             part2 = r2[i]**2 * np.arccos((d[i]**2 + r2[i]**2 - r1[i]**2) / (2 * d[i] * r2[i]))\n",
    "#             part3 = 0.5 * np.sqrt(\n",
    "#                 (-d[i] + r1[i] + r2[i]) *\n",
    "#                 (d[i] + r1[i] - r2[i]) *\n",
    "#                 (d[i] - r1[i] + r2[i]) *\n",
    "#                 (d[i] + r1[i] + r2[i])\n",
    "#             )\n",
    "#             # 最终交集为两个扇形面积之和减去中间的三角形面积。\n",
    "#             intersection = part1 + part2 - part3\n",
    "           \n",
    "#         # 并集 = 两圆面积和 - 交集面积；\n",
    "#         union = area1[i] + area2[i] - intersection\n",
    "\n",
    "#         ious[i] = intersection / (union + 1e-6)  # 加上小常数防止除0\n",
    "\n",
    "#     return ious\n",
    "\n",
    "def compute_od_metrics_per_dataset(path_of_gt, path_of_pred, model, beta=3, gt_threshold=0.6):\n",
    "    # Initialize results array\n",
    "    metrics = np.zeros(5)\n",
    "    # print(metrics.shape)\n",
    "    # (5)\n",
    "    \n",
    "    total_pred_len = 0\n",
    "    # ious_list 和 weights_list 分别记录 IoU 值和预测权重。\n",
    "    ious_list = []\n",
    "\n",
    "\n",
    "    print(\"len_gt\",len(path_of_gt))\n",
    "    \n",
    "    for i in range(0, len(path_of_gt), 1):\n",
    "        gt_file = path_of_gt[i]\n",
    "\n",
    "        image_name = gt_file.split('/')[-1].replace('.csv', '.json')\n",
    "        pred_file = f'{path_of_pred}/{model}/{image_name}'\n",
    "\n",
    "        if not os.path.exists(pred_file):\n",
    "            print(f\"Prediction file not found: {pred_file}\")\n",
    "            continue\n",
    "\n",
    "        # 真实标签和预测结果\n",
    "        df = pd.read_csv(gt_file, usecols=[0, 1, 2])\n",
    "        \n",
    "        diameter_column = df.iloc[:, 2]\n",
    "        # 获取唯一值\n",
    "        diameter = diameter_column.unique()\n",
    "        diameter = int(diameter[0])\n",
    "        r = int(diameter/2)\n",
    "\n",
    "        gt_array = df.iloc[:, :2].to_numpy()  # 只保留前两列 (x, y)\n",
    "\n",
    "        with open(pred_file, 'r') as file:\n",
    "            pred_array = json.load(file)\n",
    "        pred_array = np.array(pred_array)\n",
    "        \n",
    "        # 如果预测结果为空，则将 IoU 列表填充为 0，并跳过后续计算。\n",
    "        if not len(pred_array):\n",
    "            ious_list.extend([0] * len(gt_array))\n",
    "            continue\n",
    "\n",
    "        # 使用 coordinates_to_dmatrix 计算预测与真实标签之间的距离矩阵。\n",
    "        # 找到每个 GT 最近的预测点。\n",
    "        distances = coordinates_to_dmatrix(gt_array.astype(float), pred_array.astype(float))\n",
    "        # print(distances.shape)\n",
    "        # 用于找到数组中每行（沿着 axis=1 指定的轴）的最小值的索引\n",
    "        min_distances, min_indices = np.min(distances, axis=1), np.argmin(distances, axis=1)\n",
    "          # 调用 object_detection_intersection_over_union 计算 IoU。\n",
    "        ious = object_detection_intersection_over_union(gt_array, pred_array[min_indices], np.repeat(r, len(gt_array)))\n",
    "      \n",
    "        # print(\"ious\",ious.shape)\n",
    "        # ious (59,)\n",
    "        ious_list.extend(ious)\n",
    "\n",
    "        total_pred_len += len(pred_array)\n",
    "      \n",
    "    ious_array = np.array(ious_list)\n",
    "\n",
    "    # Calculate metrics\n",
    "    \n",
    "    if len(ious_array):\n",
    "        mean_iou = np.round(np.mean(ious_array), 3)\n",
    "    else:\n",
    "        mean_iou = 0\n",
    "    #  # 正确预测的目标占所有真实目标的比例\n",
    "    recall = np.round(np.sum(ious_array > gt_threshold) / max(len(ious_array), 1e-6), 3)\n",
    "    #  # 正确预测的目标占所有预测目标的比例\n",
    "    precision = np.round(np.sum(ious_array > gt_threshold) / max(total_pred_len, 1e-6), 3)\n",
    "    f1_score = np.round(2 * recall * precision / max((recall + precision), 1e-6), 3)\n",
    "    f1_weighted = np.round((1 + beta ** 2) * recall * precision / max((recall + (beta ** 2) * precision), 1e-6), 3)\n",
    "\n",
    "    metrics = mean_iou, recall, precision, f1_score, f1_weighted\n",
    "\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "empiar_ids=[10017,10028,10081,10093,10345,10532,11056]\n",
    "output_txt_path = \"evaluation_results.txt\"\n",
    "\n",
    "with open(output_txt_path, \"w\") as f:\n",
    "    # 将所有print输出重定向到文件\n",
    "    sys.stdout = f\n",
    "    \n",
    "    for empiar_id in empiar_ids:\n",
    "        gt_path = list(glob.glob(f\"/data/yb/Promptpoint/prompter/datasets/test_dataset/{empiar_id}/particle_coordinates/*.csv\"))\n",
    "        pre_path = f'/data/yb/CryoSegNet/output/star_files/{empiar_id}'\n",
    "\n",
    "        print(f\"Evaluation Results for EMPIAR ID {empiar_id}\", flush=True)\n",
    "        # evaluation(gt_path, model = \"CrYOLO\")\n",
    "        # evaluation(gt_path, model = \"Topaz\")\n",
    "        # evaluation(gt_path, model = \"CryoSegNet\")\n",
    "        print('{:<5s} {:<8s} {:<12s} {:<8s} {:<8s} {:<8s}'.format('Dset', 'IoU','Precision','Recall', 'F1', 'F3'), flush=True)\n",
    "\n",
    "        fr = compute_od_metrics_per_dataset(gt_path, pre_path, model = \"prompter_SAM_star\", beta=3, gt_threshold=0.5)\n",
    "\n",
    "        print('{:<5d} {:<8.3f} {:<9.3f} {:<10.3f} {:<8.3f} {:<8.3f}'.format(empiar_id, fr[0], fr[2], fr[1], fr[3], fr[4]), flush=True)\n",
    "        print(f\"--------------------------------------\", flush=True)\n",
    "         # 恢复标准输出\n",
    "    sys.stdout = sys.__stdout__\n",
    "\n",
    "print(f\"[INFO] All evaluation results saved to: {output_txt_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] All evaluation results saved to: evaluation_results_CNN.txt\n"
     ]
    }
   ],
   "source": [
    "empiar_ids=['10017_CNN',\"10028_CNN\"]\n",
    "output_txt_path = \"evaluation_results_CNN.txt\"\n",
    "\n",
    "with open(output_txt_path, \"w\") as f:\n",
    "    # 将所有print输出重定向到文件\n",
    "    sys.stdout = f\n",
    "    \n",
    "    for empiar_id_CNN in empiar_ids:\n",
    "        empiar_id=empiar_id_CNN.split(\"_\")[0]\n",
    "        \n",
    "        gt_path = list(glob.glob(f\"/data/yb/Promptpoint/prompter/datasets/test_dataset/{empiar_id}/particle_coordinates/*.csv\"))\n",
    "        pre_path = f'/data/yb/CryoSegNet/output/star_files/{empiar_id_CNN}'\n",
    "\n",
    "        print(f\"Evaluation Results for EMPIAR ID {empiar_id_CNN}\", flush=True)\n",
    "        # evaluation(gt_path, model = \"CrYOLO\")\n",
    "        # evaluation(gt_path, model = \"Topaz\")\n",
    "        # evaluation(gt_path, model = \"CryoSegNet\")\n",
    "        print('{:<5s} {:<8s} {:<12s} {:<8s} {:<8s} {:<8s}'.format('Dset', 'IoU','Precision','Recall', 'F1', 'F3'), flush=True)\n",
    "\n",
    "        fr = compute_od_metrics_per_dataset(gt_path, pre_path, model = \"prompter_SAM_star\", beta=3, gt_threshold=0.5)\n",
    "\n",
    "        print('{:<5s} {:<8.3f} {:<9.3f} {:<10.3f} {:<8.3f} {:<8.3f}'.format(empiar_id_CNN, fr[0], fr[2], fr[1], fr[3], fr[4]), flush=True)\n",
    "        print(f\"--------------------------------------\", flush=True)\n",
    "         # 恢复标准输出\n",
    "    sys.stdout = sys.__stdout__\n",
    "\n",
    "print(f\"[INFO] All evaluation results saved to: {output_txt_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_path = '/data/yb/CryoTransformer/output/predictions/11056/box_files'\n",
    "\n",
    "# 列出文件夹中所有“文件”（不包括子文件夹）\n",
    "file_list = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "# 输出数量\n",
    "print(f\"文件总数：{len(file_list)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cryosegnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
